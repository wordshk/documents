# How we used AI to review and rewrite our example sentences

Words.hk is a Cantonese dictionary that also contains English explanations and
English translation of example sentences. The vast majority of our editors are
native Cantonese speakers, and English is often our second language. This can
often be very apparent in the English translations of the example sentences. By
the author's estimation, easily more than half of the English translations have
some grammatical or serious stylistic error of some kind, or is mistranslated.
We currently have more than 35,000 example sentences (or phrases) in our
database, and (to a small team of volunteers like us) it is a gigantic
undertaking to review and fix errors in the English translations.

So, like everyone else in 2024, we used AI to help us! (And yes, we waited 10 years for the AI to become good enough.)

Naïvely, one would expect state-of-the-art (SoTA) language models to do well on
translation tasks, and perhaps we can automate the whole process by simply
asking the model to translate the original Cantonese example sentences to
English. However, the sad fact is that none of the available models have
sufficient understanding of Cantonese, especially for lesser-used colloquial
Cantonese words/expressions. Given that as a Cantonese dictionary, many of our
examples are intended to showcase such words and expressions, we cannot simply
(solely) rely on language models to do the job.

But the nice thing is that we *already* have translations in broken English!
What if we combined the Cantonese sentences, the broken English, and ask
multiple language models to review them and give suggestions? That's exactly
what we did, and it kind of works. The SoTA models were apparently able to
combine Cantonese sentences that it didn't fully understand, English
translations written in broken English (but provided some insight as to what
the Cantonese meant), and synthesize them into English translations that were
fluent and made sense.

Sadly, the accuracy of the results are not high enough that we feel confident
in automatically replacing the existing translations with the generated ones.
So, as of writing, we are manually reviewing the sentences generated by the AI
models and applying the changes that we've found useful. It's a slow and
laborious process, but it had to be done anyway. We're not really going to rely
on AI to tell you what a Cantonese sentence means, not even if its accuracy is
99% (because we shouldn't knowingly allow the 1% inaccuracy!)

The percentage of "good" translations from the AI models vary based on a couple factors:

- Whether the Cantonese sentence involved uncommon colloquial expressions

- Whether the Cantonese sentence involved profanity/rudeness/sex/violence -- the AI model generally downplays these "bad" elements tries to make the sentence more polite, but in most of these cases, as a dictionary project, we wanted to accurately translate the tone of the sentence as well, so we often have to edit the suggested sentences into having a more nasty tone.

- How broken the original example sentence was (sometimes the AI model adopts the mistranslations)

As mentioned, we are still slowly reviewing the results, but in general, we'd
estimate that more than half of the AI generated replacements are "good". We'll
post an update with the precise statistics (percentage of generated
translations we directly used) once we are done with the manual review process.
(Note: this could take months...)

We set out the more technical details of our process below.

## Set up

- Mac Studio M2 Max with 96GB RAM
- Models:
  - qwen1_5-72b-chat-q5_k_m.gguf
  - mixtral-8x7b-instruct-v0.1.Q5_K_M.gguf
  - deepseek-llm-67b-chat.Q5_K_M.gguf
- Software: llama.cpp with custom modifications (https://github.com/wordshk/llama.cpp/commit/cca2c6241f583daf2b757c40cec449f831ac2aef) to run parallel inference
  - Parallel inference runs somewhat faster, taking estimated ~30%-40% less time in total (using `-c 8192 -np 8`).

## General Approach

We used a very elaborate chain of thought set up. There were two tasks. First
was reviewing the original English sentences. We asked 3 AI models (see above)
to review the translation sentences and give a score (twice each), aggregated
those scores and sorted them by average score.

In the second step, we used Qwen-1.5 to generate suggested translations based
on the original sentences and reviews.

The rationale is that while LLMs do generally well with translation tasks, they
are somewhat less reliable with *grading* the fluency of sentences. Coupled
with the fact that current models are not very good at understanding Cantonese,
we thought it would be better to spend a bit more compute time to run the
reviewing task over a couple models and take the average score. You can say
this is a very "low-tech" way to emulate a mixture of experts set up using
multiple prompts.

We wanted to get the review scores because it helps us prioritize the
sentences. The sentences with high grades probably need less work, and the
sentences with lower grades probably need more work. (Originally we thought we
could set a cut-off point, and assume sentences with higher score do not need
to be replaced, but upon inspection we probably will still review them and
replace the sentences with the ones suggested by the LLMs as needed.)

Since the language model does not understand Cantonese well, we still need to
manually review the generated suggested sentences before applying the changes,
otherwise we will be knowingly introducing confusing errors in ~30% of the
cases. This takes a lot of time. (We have manually reviewed ~10% of the results
in a very intensive 2-week time frame.)

## Results

It took about a week to run inference for the review prompts, and a couple days
to run the suggestion prompts. For some mysterious reason that we couldn't
figure out, the longer prompt token length of the second task (suggesting
English translation replacements) seemed to cause the parallel inference to bug
out or crash. Hence, we just used the "main" program of llama.cpp to run
inference for the second task.

Interesting trivia - the average review scores seem to follow what looks like a
normal distribution. (At least it looked like a bell curve to the author's
untrained eyes). In general the average grades are mostly accurate though, so
this isn't caused by random grades exhibiting a binomial distribution...

Anyway, if anyone is interested in the data we generated, we include a sample
of it [here](generated_english_sentences_sample.tsv). This is of course
processed from the raw outputs using a couple simple Python scripts.

### Showcase example

To showcase how broken English can assist proper translation of Cantonese
expressions that the LLM does not understand, here's a real example from our
data:

Original Cantonese sentence and English translation: `與其遲到，不如射波啦。 I would rather throw a sickie than be late.`

If one were to instruct Qwen-1.5 to simply translate the Cantonese sentence
without providing it the original English sentence, it struggles to understand
what 射波 means. Here are results from two runs:

```
> Translate this Cantonese sentence into English: 與其遲到，不如射波啦。
It's better to shoot a wave than to be late. (This is a colloquial expression
in Cantonese, and the phrase "shoot a wave" refers to sending a message or
making a call to inform someone that you'll be late.)
```

```
> Translate this Cantonese sentence into English: 與其遲到，不如射波啦。
It's better to be early than to miss the deadline. (Note: The literal
translation of "射波" is "shoot the ball," which is a colloquial expression in
Cantonese meaning "to miss the deadline." In this context, it's used
metaphorically.)
```

However, with the original English in the prompt (see below), the models were
able to infer the correct meaning of the Cantonese sentence and provide a more
fluent translation: `It's better to call in sick than arrive late.`

This is exactly what we want.


## Prompts

We have two prompts, one for each task. The reviewing task is done on all
three models above, twice per model, and the reviews are aggregated into the
suggestion task. The sentences are then sorted by average review score, and
then we generated the suggestion prompts. Only Qwen-1.5 is used for the
suggestion task, and only run once.

Note that in the prompt we also inject the first few expected tokens (i.e. "A.
Score" and "A. Suggested translation: ") to help ensure the model follows the
appropriate format.

We put 10 sentences in each prompt. `$CONTENT` is replaced with the actual
data, which follows the format in the examples, except that the actual data is
labelled `A` to `J` (instead of i, ii, iii).

### Prompt 1: review the original English sentences

```
<|im_start|>system
You are a native English speaker who can read and understand Cantonese. You only write fluent English and do not write Cantonese. You are a helpful English teacher who helps people learn better English.
<|im_end|>
<|im_start|>user
Here are a couple sentences in both Cantonese and English. They are written by your student who is a native Cantonese speaker and needs help in improving his English. Please review the English translations below, keeping in mind the ideal sentence should be simple, fluent, written like a native speaker, and to the point. Rate the sentences on a scale of 1 to 5:

1: Sentence is confusing or difficult to understand, or have obvious grammatical mistakes.
2: Contains minor grammatical errors.
3: No ambiguity or mistakes, but might contain awkward phrases or expressions that sound unnatural to the native speaker.
4: Written fluently, without obvious flaws.
5: Excellent writing and style.


For example:

i. 啲貨咁好賣，唔使慌賺唔到錢喎。 The goods are selling so well, there's no need to fear that you cannot earn money.
ii. 美國每四年會舉行一次總統選舉。 The United States holds a presidential election every four years.
iii. 你今日食咗飯未？ You today ate rice yet?

Expected output:

i. Score: 3 ("there is no need to fear" can be better written as "you do not have to worry")
ii. Score: 4 (no obvious flaws or problems)
iii. Score: 1 (Suggested replacement: "Have you eaten today yet?")

Here are the sentences for you to review. In your answer, give the rating, optionally with comments (on the same line) in the format shown above.

$CONTENT

<|im_end|>
<|im_start|>assistant
A. Score: 
```

### Prompt 2: suggest English translations

```
<|im_start|>system
You are a native English speaker who can read and understand Cantonese. You only write fluent English and do not write Cantonese. You are a helpful English teacher who helps people learn better English.
<|im_end|>
<|im_start|>user
### Background

Here are a couple sentences in both Cantonese and English. They are written by your student who is a native Cantonese speaker and needs help in improving his English. Some junior teachers have reviewed the sentences and given them scores from 1 to 5, with 5 being the best score. Since the junior teachers may be inexperienced, their scores and comments may not be accurate. Your task as a senior teacher is to review the sentences and the junior teachers' comments, and provide a suggested English translation for each sentence. If the sentence is vulgar or otherwise inappropriate, please write "Skiped due to inappropriate content".

### Examples inputs

i.
[Original Sentence] 啲貨咁好賣，唔使慌賺唔到錢喎。 The goods are selling so well, there's no need to fear that you cannot earn money.
[Review] Score: 4 (No obvious flaws or problems)
[Review] Score: 3 (The translation is accurate, but "there is no need to fear" can be better written as "you do not have to worry")
[Review] Score: 3 ("no need to fear" is a bit awkward, although the translation is accurate)
---

ii.
[Original Sentence] 美國每四年會舉行一次總統選舉。 The United States holds a presidential election every four years.
[Review] Score: 4 (no obvious flaws or problems)
[Review] Score: 5 (Excellent translation)
[Review] Score: 3 ("every four years" can be replaced with "each 4 years")
[Review] Score: 3 ("every four years" can be replaced with "each 4 years")
---

iii.
[Original Sentence] 你今日食咗飯未？ You today ate rice yet?
[Review] Score: 1 (Suggested replacement: "Have you eaten today yet?")
[Review] Score: 2 (The translation is understandable, but "ate rice" can be replaced with "eaten")
[Review] Score: 5 (The translation is accurate and natural)
---

### Expected output:

i. Suggested translation: The goods are selling so well, there's no need to worry about not making money.
ii. Suggested translation: The United States holds a presidential election every four years.
iii. Suggested translation: Have you eaten today yet?

Here are the actual sentences (from A. to J.) and reviews for you to work on. In your answers, just provide the suggested translations, keeping in mind that the sentences you write should be fluent and natural English. You can ignore the junior teachers' comments if you think they are not helpful. If you think the original sentence is already perfect, you can just repeat the original sentence. Do not provide any comments, nor scores, nor explanations in your answers, just the suggested translations.

### Start of the sentences and reviews

$CONTENT

<|im_end|>
<|im_start|>assistant
A. Suggested translation: 
```

## Q & A

- Q: Wouldn't it be better to just use GPT-4?
  - A: Probably, but it wouldn't be reproducible since they roll out new models on a regular basis. Also, given the source of Qwen1.5, it likely had a heavier weight of Chinese materials in its training, which does in fact help with its understanding of Cantonese. We also wanted to see how far we can get with open-weight models running on local hardware. (Also, OpenAI blocks Hong Kong credit cards, likely due to AI policy issues with China, so it's kind of inconvenient for us to set things.)

- Q: Why did you choose these models specifically?
  - A: The three models (Qwen1.5, Mixtral, Deepseek) are all contenders for best open-weight models out there (at the time of writing!!!). Since we have no idea which models understand Cantonese best, we thought it was best to just use all of them, and average the results in a prompt-engineering-mixture-of-experts kind of manner. In addition, Qwen1.5 has a quirk where it occasionally spits out Chinese words, which made us think that it likely has an extra emphasis on Chinese language training data, so we used it for the final suggestion inference.

- Q: Doesn't $model use different prompt templates?
  - A: Yes, Mixtral and Deepseek uses different prompt templates (not ChatML). But it didn't seem to have noticeable effects on the results.

- Q: What are some ways you could have improved the process?
  - A: Using the correct prompt templates would have helped. It might have been slightly better to use simplified Chinese characters since the language models likely contained more of such data, and this *may* slightly improve its understanding of Cantonese. We also forgot to tune down the temperature, so we actually used the default value (of llama.cpp), which is probably higher than what we needed in this task. There were also some typos in the prompt (known ones are corrected, so the prompts above are not exactly the ones we used). Nonetheless we are in general happy with the results so far.

- Q: Why did you direct the model to censor itself (i.e. `If the sentence is vulgar or otherwise inappropriate, please write "Skiped due
 to inappropriate content".` in prompt 2)?
  - A: The risk is that if not so instructed, the model may refuse the whole task instead of just refusing to translate one sentence. In general the model doesn't do a great job at translating vulgar/explicit Cantonese sentences anyway, so this isn't a significant loss for our purposes.
